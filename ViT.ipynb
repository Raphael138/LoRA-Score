{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rft38/.conda/envs/ML-6784/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    AutoModelForImageClassification,\n",
    "    ViTFeatureExtractor,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model, prepare_model_for_kbit_training\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Importing the arg parser\n",
    "from utils import parse_args, gather_metrics, plot_metrics\n",
    "\n",
    "# Set warnings to ignore to keep output clean\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dataset_type = \"stanford-dogs\"\n",
    "train_num_classes = None\n",
    "use_lora = True\n",
    "lora_rank = 500\n",
    "lora_alpha, lora_dropout = 2*lora_rank, 0.1\n",
    "batch_size, eval_batch_size, gradient_accumulation_steps, max_steps = 32, 50, 1, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     image_col_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dataset_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstanford-dogs\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 15\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamaye15/stanford-dogs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m120\u001b[39m\n\u001b[1;32m     17\u001b[0m     label_column_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/datasets/load.py:2166\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2164\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2165\u001b[0m )\n\u001b[0;32m-> 2166\u001b[0m ds \u001b[38;5;241m=\u001b[39m builder_instance\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39msplit, verification_mode\u001b[38;5;241m=\u001b[39mverification_mode, in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory)\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_infos:\n\u001b[1;32m   2168\u001b[0m     builder_instance\u001b[38;5;241m.\u001b[39m_save_infos()\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/datasets/builder.py:1126\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, in_memory)\u001b[0m\n\u001b[1;32m   1123\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS)\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;66;03m# Create a dataset for each of the given splits\u001b[39;00m\n\u001b[0;32m-> 1126\u001b[0m datasets \u001b[38;5;241m=\u001b[39m map_nested(\n\u001b[1;32m   1127\u001b[0m     partial(\n\u001b[1;32m   1128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_single_dataset,\n\u001b[1;32m   1129\u001b[0m         run_post_process\u001b[38;5;241m=\u001b[39mrun_post_process,\n\u001b[1;32m   1130\u001b[0m         verification_mode\u001b[38;5;241m=\u001b[39mverification_mode,\n\u001b[1;32m   1131\u001b[0m         in_memory\u001b[38;5;241m=\u001b[39min_memory,\n\u001b[1;32m   1132\u001b[0m     ),\n\u001b[1;32m   1133\u001b[0m     split,\n\u001b[1;32m   1134\u001b[0m     map_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1135\u001b[0m     disable_tqdm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1136\u001b[0m )\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(datasets, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1138\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m DatasetDict(datasets)\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/datasets/utils/py_utils.py:512\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    509\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    510\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m    511\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 512\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    514\u001b[0m ]\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    516\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/datasets/utils/py_utils.py:373\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function([data_struct])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    375\u001b[0m     batched\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[1;32m    379\u001b[0m ):\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m function(batch)]\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/datasets/builder.py:1156\u001b[0m, in \u001b[0;36mDatasetBuilder._build_single_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, in_memory)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     split \u001b[38;5;241m=\u001b[39m Split(split)\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Build base dataset\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_dataset(\n\u001b[1;32m   1157\u001b[0m     split\u001b[38;5;241m=\u001b[39msplit,\n\u001b[1;32m   1158\u001b[0m     in_memory\u001b[38;5;241m=\u001b[39min_memory,\n\u001b[1;32m   1159\u001b[0m )\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_post_process:\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m resource_file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_processing_resources(split)\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/datasets/builder.py:1230\u001b[0m, in \u001b[0;36mDatasetBuilder._as_dataset\u001b[0;34m(self, split, in_memory)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_legacy_cache():\n\u001b[1;32m   1229\u001b[0m     dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m-> 1230\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m ArrowReader(cache_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo)\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m   1231\u001b[0m     name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m   1232\u001b[0m     instructions\u001b[38;5;241m=\u001b[39msplit,\n\u001b[1;32m   1233\u001b[0m     split_infos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1234\u001b[0m     in_memory\u001b[38;5;241m=\u001b[39min_memory,\n\u001b[1;32m   1235\u001b[0m )\n\u001b[1;32m   1236\u001b[0m fingerprint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_fingerprint(split)\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Dataset(fingerprint\u001b[38;5;241m=\u001b[39mfingerprint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/datasets/arrow_reader.py:252\u001b[0m, in \u001b[0;36mBaseReader.read\u001b[0;34m(self, name, instructions, split_infos, in_memory)\u001b[0m\n\u001b[1;32m    250\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstruction \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstructions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m corresponds to no data!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_files(files\u001b[38;5;241m=\u001b[39mfiles, original_instructions\u001b[38;5;241m=\u001b[39minstructions, in_memory\u001b[38;5;241m=\u001b[39min_memory)\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/datasets/arrow_reader.py:273\u001b[0m, in \u001b[0;36mBaseReader.read_files\u001b[0;34m(self, files, original_instructions, in_memory)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns single Dataset instance for the set of file instructions.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    kwargs to build a Dataset instance.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Prepend path to filename\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_files(files, in_memory\u001b[38;5;241m=\u001b[39min_memory)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# If original_instructions is not None, convert it to a human-readable NamedSplit\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_instructions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/datasets/arrow_reader.py:202\u001b[0m, in \u001b[0;36mBaseReader._read_files\u001b[0;34m(self, files, in_memory)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m    200\u001b[0m     f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path, f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 202\u001b[0m pa_tables \u001b[38;5;241m=\u001b[39m thread_map(\n\u001b[1;32m    203\u001b[0m     partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_table_from_filename, in_memory\u001b[38;5;241m=\u001b[39min_memory),\n\u001b[1;32m    204\u001b[0m     files,\n\u001b[1;32m    205\u001b[0m     tqdm_class\u001b[38;5;241m=\u001b[39mhf_tqdm,\n\u001b[1;32m    206\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading dataset shards\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# set `disable=None` rather than `disable=False` by default to disable progress bar when no TTY attached\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m )\n\u001b[1;32m    210\u001b[0m pa_tables \u001b[38;5;241m=\u001b[39m [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m pa_tables \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(t) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pa_tables \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:69\u001b[0m, in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _executor_map(ThreadPoolExecutor, fn, \u001b[38;5;241m*\u001b[39miterables, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtqdm_kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[38;5;241m=\u001b[39mlock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers, initializer\u001b[38;5;241m=\u001b[39mtqdm_class\u001b[38;5;241m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[38;5;241m=\u001b[39m(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tqdm_class(ex\u001b[38;5;241m.\u001b[39mmap(fn, \u001b[38;5;241m*\u001b[39miterables, chunksize\u001b[38;5;241m=\u001b[39mchunksize), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/site-packages/tqdm/std.py:1169\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult(timeout)\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.conda/envs/ML-6784/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dataset selection\n",
    "if dataset_type == \"mnist\":\n",
    "    dataset = load_dataset(\"mnist\")\n",
    "    num_classes = 10\n",
    "    label_column_name = 'label'\n",
    "    image_col_name = \"image\"\n",
    "\n",
    "elif dataset_type == \"oxford-pet\":\n",
    "    dataset = load_dataset(\"visual-layer/oxford-iiit-pet-vl-enriched\")\n",
    "    num_classes = 37\n",
    "    label_column_name = 'label_breed'\n",
    "    image_col_name = \"image\"\n",
    "\n",
    "elif dataset_type == \"stanford-dogs\":\n",
    "    dataset = load_dataset(\"amaye15/stanford-dogs\")\n",
    "    num_classes = 120\n",
    "    label_column_name = 'label'\n",
    "    image_col_name = \"pixel_values\"\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Currently not supported -> You can add them now\")\n",
    "\n",
    "# Creating val/train split\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.15, shuffle=True, seed=1)\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for the labels -> Only necessary for oxford-pet, not mnist or stanford-dogs\n",
    "if dataset_type == \"oxford-pet\":\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    def label_preprocessing(dataset):\n",
    "        # Fit the encoder on the string labels and transform them to integer labels\n",
    "        label_encoder.fit(dataset[label_column_name])\n",
    "        encoded_labels = label_encoder.transform(dataset[label_column_name])\n",
    "\n",
    "        # Add the encoded labels as a new column in the dataset\n",
    "        return dataset.add_column('label', encoded_labels)\n",
    "\n",
    "    # Apply preprocessing\n",
    "    train_dataset = label_preprocessing(train_dataset)\n",
    "    val_dataset = label_preprocessing(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter classes if specified\n",
    "if train_num_classes:\n",
    "    selected_classes = train_num_classes\n",
    "\n",
    "    def filter_classes(batch):\n",
    "        return batch['label'] in selected_classes\n",
    "\n",
    "    train_dataset = train_dataset.filter(filter_classes)\n",
    "    val_dataset = val_dataset.filter(filter_classes)\n",
    "\n",
    "    # Update num_classes to reflect the number of selected classes\n",
    "    num_classes = len(selected_classes)\n",
    "\n",
    "    # Preprocessing for the labels -> Once filtered the labels need to be set between (0, num(classes)-1)\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    def label_preprocessing(dataset):\n",
    "        # Fit the encoder only on the filtered labels\n",
    "        label_encoder.fit(selected_classes)\n",
    "        # Transform the dataset labels\n",
    "        dataset = dataset.map(lambda batch: {'label': label_encoder.transform([batch['label']])[0]})\n",
    "        return dataset\n",
    "\n",
    "    # Apply preprocessing\n",
    "    train_dataset = label_preprocessing(train_dataset)\n",
    "    val_dataset = label_preprocessing(val_dataset)\n",
    "\n",
    "else:\n",
    "    selected_classes = [i for i in range(num_classes)]\n",
    "\n",
    "# Preprocessing dataset to be compatible with ViT\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Combined function to resize, convert to RGB, and then to tensor\n",
    "def preprocess_images(batch):\n",
    "    batch['pixel_values'] = [transform(image.convert(\"RGB\")) for image in batch[image_col_name]]\n",
    "    if image_col_name!='pixel_values':\n",
    "        del batch[image_col_name]\n",
    "    return batch\n",
    "\n",
    "# Apply resizing\n",
    "train_dataset = train_dataset.map(preprocess_images, batched=True)\n",
    "val_dataset = val_dataset.map(preprocess_images, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([120]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([120, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Setup LoRA\n",
    "if use_lora:\n",
    "    layers = [\"query\", \"key\", \"value\"]\n",
    "    target_modules = [f\"vit.encoder.layer.{i}.attention.attention.{layer}\" for i in range(0, 12) for layer in layers]\n",
    "\n",
    "\n",
    "    # Set up LoRA configuration\n",
    "    lora_config = LoraConfig(\n",
    "        r=lora_rank,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=target_modules,\n",
    "        lora_dropout=lora_dropout,\n",
    "        use_rslora=True,\n",
    "    )\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"google/vit-base-patch16-224\" \n",
    "model = AutoModelForImageClassification.from_pretrained(model_name, num_labels = num_classes, ignore_mismatched_sizes=True)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Apply LoRA to the model\n",
    "if use_lora:\n",
    "    model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# Define accuracy metric\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Define the compute_metrics function to calculate accuracy\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layers\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print the layers and their frozen state\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m layers \u001b[38;5;241m=\u001b[39m list_model_layers(model)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_name, is_trainable \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m     11\u001b[0m     status \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainable\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_trainable \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrozen\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to list layers and their frozen state\n",
    "def list_model_layers(model):\n",
    "    layers = []\n",
    "    for name, param in model.named_parameters():\n",
    "        layers.append((name, param.requires_grad))\n",
    "    return layers\n",
    "\n",
    "# Print the layers and their frozen state\n",
    "layers = list_model_layers(model)\n",
    "for layer_name, is_trainable in layers:\n",
    "    status = \"Trainable\" if is_trainable else \"Frozen\"\n",
    "    print(f\"Layer: {layer_name}, Status: {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Init run\n",
    "run_name = \"ViT\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"results/{run_name}\",\n",
    "    per_device_train_batch_size= batch_size,\n",
    "    per_device_eval_batch_size= eval_batch_size,\n",
    "    gradient_accumulation_steps= gradient_accumulation_steps,\n",
    "    max_steps=max_steps,\n",
    "    logging_steps=10,\n",
    "    eval_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=1,\n",
    "    evaluation_strategy=\"steps\"\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather data from trainer and plot\n",
    "data = gather_metrics(trainer)\n",
    "plot_metrics(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-6784",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
